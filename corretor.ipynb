{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Carregando Base de Dados**\n",
    "\n",
    "Está será a base de dados que será aplicada no treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etendendo o Problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('artigos.txt', 'r') as f:\n",
    "    artigos = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2605046"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(artigos[ :500]) - Caso queira ver as 500 primeiras imagens\n",
    "# Cuidado porque aqui, vejo a quantidade de caracteres, não de tokens\n",
    "len(artigos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando o um teste\n",
    "frase = 'Olá tudo bem?'\n",
    "token = frase.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Olá', 'tudo', 'bem?']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Olá', 'tudo', 'bem', '?']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('punkt') - Tive que fazer o Downlod para atualizar o método\n",
    "palavras_separadas = nltk.tokenize.word_tokenize(frase)\n",
    "palavras_separadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observo que o tokenizador fez a separação das palavras de forma satisfatória. Porem, ainda existe ou desafio\n",
    "\n",
    "Ele trouxe tambem a pontuação e os acentos das palavras. \n",
    "\n",
    "Para resolver este problema, vou criar uma função que fará esta remoção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_palavras(lista_tokens):\n",
    "    lista_palavras = []\n",
    "\n",
    "    for i in lista_tokens:\n",
    "        i = i.lower()\n",
    "        if i.isalpha():\n",
    "            lista_palavras.append(i)\n",
    "\n",
    "    return lista_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['olá', 'tudo', 'bem']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separa_palavras(palavras_separadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando Lista de palavras corretas\n",
    "\n",
    "Esta lista servirá como base para meu corretor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18464"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_tokens = nltk.tokenize.word_tokenize(artigos)\n",
    "lista_palavras = separa_palavras(lista_tokens)\n",
    "lista_palavras = list(set(lista_palavras))\n",
    "len(lista_palavras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fatiador de Palavras\n",
    "\n",
    "Esta é a função que fará o fatiamento das strings para que o corretor faço o trabalho de identificar qual a palavra correta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('l', 'gica')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista = 'lgica'\n",
    "(lista[:1], lista[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que irá acrescentar as letras \"Faltantes\"\n",
    "# Com ela, terei condições de montar as palavras e conferir com meu gabarito\n",
    "def insere_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzáâàãéêèẽíîìĩóôõòúûùũç'\n",
    "\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)\n",
    "    \n",
    "    return novas_palavras\n",
    "\n",
    "\n",
    "# Esta função recebe a palavra e verifica se está correta\n",
    "# Se não estiver, vai acrescentar as letras que faltam e conferir com o gabarito\n",
    "def gerador_palaavras(palavra):\n",
    "    fatias = []\n",
    "\n",
    "    # Fazendo o Fatiamento da Palavra\n",
    "    for i in range (len(palavra)+1):\n",
    "        fatias.append((palavra[:i], palavra[i:]))\n",
    "\n",
    "    # Aqui gero as palavras através da função insere letras\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    return palavras_geradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencia = nltk.FreqDist(lista_palavras)\n",
    "total_palavras = len(lista_palavras)\n",
    "frequencia.most_common(1)\n",
    "\n",
    "def probabilidade(palavra_gerada):\n",
    "    return frequencia[palavra_gerada]/total_palavras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corretor(palavra):\n",
    "    palavras_geradas = gerador_palaavras(palavra)\n",
    "    palavra_correta = max(palavras_geradas, key=probabilidade)\n",
    "      \n",
    "    return palavra_correta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corretor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18464"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lista_palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14f2a0716530ff180011a5888144c43470b29192f878ee74fce997d3c4673ddf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
